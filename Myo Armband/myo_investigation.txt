Myo Armband Keyboard Investigation

**NOTE: In order to help you understand, we have included some images in "./Figure directory". Also, data output is included in "./data_output_info.txt" Please check that out as you read this investigation **

Group 7
  Kyle Seokjin Ahn     7794966
  Vighnesh Revanan     7780126
  Goutham Dhannapuneni 7814509

OBJECTIVE: (1) Approproriate extraction the data sets from given raw data.   ( COMPLETED )
           (2) Obtaining desired outputs from single-axis representation. ( COMPLETED )
                -> 70% of accuracy was set as a desired output when repeated 10 times.
           (3) Obtaining desired outputs from multi-axis representation. ( COMPLETED )
                -> 85% of accuracy was set as a desired output when repeated 10 times.

-) Data Analysis

 Set Detection
Initially, we had to closely analyse the data given to us in order to figure out what data to use for different parts in the assignment. As advised by the professor Lau, we have mainly used "no-change periods" from the orientation.csv files to split the 10 inputs. We simply took all the consecutively repeating timestamps. Then, inbetween these no-change periods(marked by timestamps), we checked if there was a peak_point, which implied for an input. We repeated this process until we have got the correct 10 inputs. The information of these 10 inputs were then stored in a class object named "Interval", which allowed us to store the "start_time" and "end_time" of every input. 

 Extract Data
Using these 10 "Intervals", we were able to flexibly extract arrays of actual data from any of Accelerometer, Gyrometer and EMG files. We simply used extract_gyro, extract_emg and extract_accelero functions in dataReader.py to extract the actual data. The logic is simply to extract all the data entries between start_time and end_time of each interval. These extracted  data are then used in both Single-Axis and Multi-Axis representations.


-) Signle-Axis representation
 As mentioned previously, we have extracted data from all three of gyrometer, accelerometer and emg files to compare which data yields the most ideal output. We will discuss what we have investigated from these outputs.

 (1)EMG
First, we have used a number of different columns from EMG, such as "EMG1", "EMG2" and "EMG4" as these seemed to differentiate amongst the 5 key. If you look at "figure_1", you can see that EMG1 does not really differentiate the 5 keys as all the graphs follow the quite same patterns. As expected, our program have only got about 30% accuracy of guessing the correct output. Then, we have tried EMG2 next. I you look at "figure_2", you may observe that EMG2 has a bit more distinct patterns between (i)forward and backward, (ii)left and right, and (iii)enter. Thus using EMG2 for our single-axis representation gave us a bit better output of 50%, but this was still not enough as we wanted to clearly meet the goal of over 70% accuracy. Finally, we have tried EMG. If you look at "figure_3", you may think it would give you a good output as the graphs clearly show where the 10 inputs are processed. However, since the machine only looks at the patterns, we merely obtained 55% of accuracy even using the EMG4. 

Thus, we have failed to obtain a desired output using each EMG as a single-axis representation as expected.


 (2)Accelerometer
Second, we have used accelerometer for our single-axis representation input after failing to obtain a desired ouput by using EMG. From our understanding of accelerometer, we first guessed that we would have at least 50% of accuracy by using accelerometer since it measure the velocity of x, y and z when moving. After analysing x, y and z of each 5 key with "figure_4", we have selected to use 'x' axis for accelerometer's single-axis representation as 'x' showed clear disctinction between "backward, left & right" and "forward & enter". The graph of 'x' axis fluctuated more drastically "forward & enter" keys than the rest of the keys. This meant that the machine will at least differentiate these two groups, and maybe more. Fortunately, we were able to obtain an accuracy of 74% after 10 trials. At a curiosity, we have tried with 'y' axis of accelerometer, but we only got just over 30% of accuracy.

Thus, we were successful to obtain a desired output using 'x' axis of accelerometer as a single-axis representation.

 
 (3)Gyrometer
Finally, we haveu used gyrometer for our single-axis representation. Although we have met our goal by using 'x' axis of the accelerometer, we decided to try with gyrometer as well to select the best data for the section 4.2 for multi-axis representation. If you look at "figure_5", you may observe a similar pattern as what we have observed with 'x' axis of the accelerometer. The graphs showed quite a distinction between "enter, forward & right" and "backward & left". With this analysis, we expected to see a similar or better performance than using 'x' axis of the accelerometer. As expected, we have obtained 76% accuracy, which is quite similar figure of the accelerometer. One thing we have noticed from comparing accelerometer and gyrometer is that the accelerometer gave more consistant output (only within 0.6~1.0, but most likely 0.6 and 0.8), but the gyrometer gave more fluctuating output (within 0.4~1.0, but most likely 0.80 and 1.00).

Thus, we were successful to obtain a desired output using 'y' axis of the gyrometer as a single-axis representation.



-) Mutl-Axis Representation
From the analysis of the signle-axis representation, we were able to see that "accelerometer" and "gyrometer" are quite good with guessing the output. However, we now wanted to use all three axis of either data to see if it would enhance the output. Since we obtained more steady output from accelerometer, we decided to use 'x', 'y' and 'z' axis of accelerometer to compose a multi-axis representation input. 

In our data structure, what we have done is to simply stitch x, y and z into one vector (one long array) to give this as an input to the multi-layer perceptron. So, our data structure would look like this, [ [x11, x12, x13, y11, y12, y13, z11, z12, z13], [x21, x22, x23, y21, y22, y23, z21, z22, z23], ... ], and the output would look like this forward: [1, 0, 0, 0, 0], backward: [0, 1, 0, 0, 0], left: [0, 0, 1, 0 ,0], right: [0, 0, 0, 1 ,0] and finally enter: [0, 0, 0, 0, 1]. 

What we first expected was to obtain a much better output of at least 85% since we are now using all three axis to differentiate the keys. However, we had one concern. Since we are using much larger data, it would make the importance of 'x' axis relatively low. 'x' axis is the one that shows the most distinct results, so we were not too sure how to make 'x' axis more important than the other two axis. Although we have not done anything to resolve this issue in this assignment, we wanted to highlight this issue in our investigation since this is something that could potentially improve the overall performance of this program. 

As expected, we obtained 85% accuracy after trying 10 times. 




-) Overall Insights
From this assignment, we have gained an insight of how nueral network works, especailly multi-layer perceptron which is used our program. We were able to see that the multi-axis representation works much better than single-axis representation, however, we also realised that it would really depend on the raw data sets. If one axis could differentiate all the keys and the other two axis contained irrelevant data, single-axis representation would have given us a better output. In this case, however, all three axis somehow all contributed to differentiate the 5 keys. 

One difficulty we were having was that the fixed array length size. For example, our data structure for the input was like [ [x11, x12, x13, y11, y12, y13, z11, z12, z13], [x21, x22, x23, y21, y22, y23, z21, z22, z23], ... ] as mentioned above. We gave each array such as [x11, x12, x13, y11, y12, y13, z11, z12, z13] as one input for training, so it would be total 9 inputs for trainng and the last array [x101, x102, x103, y101, y102, y103, z101, z102, z103] for the testing. However, the professor has mentioned that there is a way to use different array lengths for the training and testing inputs. For example, [ x11, x12, x13, y11, y12, y13, z11, z12, z13, x21, x22, x23, y21, y22, y23, z21, z22, z23, ... ] for the training data and [x101, x102, x103, y101, y102, y103, z101, z102, z103] could have been worked. However, we were not able to figure this out since our tensorflow multi-layer perceptron only took the inputs with the same array lengths. Although we gave the inputs as 9 separate arrays, the professor assured us that it would not make much difference in performance of the program.

Another difficulty that we were facing was with the 10 sets of intervals that we extracted from orientation.csv files. All of these 10 intervals had different lengths and the peak_point was not centred, which would make machine hard to look for an uniform pattern to differentiate 5 keys. So, what we have done is to identify the peak_point in each of these intervals and centralise each interval's data entries. centralise_intervals function in dataReader.py takes care of that. 


-- END --